{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNN)\n",
    "\n",
    "due to how computationally efficient and effective they are, they are arguably the most popular deep learning algorithm.\n",
    "\n",
    "these networks are useful for images as it can analyze different features of the image.\n",
    "\n",
    "CNNs also require lower quantity of parameters when compared to an artificial neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks are different than artificial networks since it consists of a convolutional layer and a pooling layer before it gets to the fully connected layers. \n",
    "\n",
    "The convolutional layers process the image by something known as the kernel filters, which are generally small and spatial dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation function:\n",
    "\n",
    "![Markdown Logo](https://www.researchgate.net/profile/Hossam_H_Sultan/publication/333411007/figure/fig7/AS:766785846525952@1559827400204/ReLU-activation-function.png)\n",
    "\n",
    "Deletes non-linearity by making all negative values into zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "reduces computational costs by reducing the parameters of the image. helps reduce overfitting by providing an abstracted form of the original feature map.\n",
    "\n",
    "The maximum value being taken into account in each image corresponds to a region in the image most prevalent to the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers\n",
    "\n",
    "Fully Connected layers is responsible for taking these features of inputs processing them to attain a final probability as to which class the image belongs to. In other words, FC layers are in charge of classification. Whereas the first part is responsible for feature extraction.\n",
    "\n",
    "FC layers works the same way as multi layer perceptron where the node in the preceding layer is fully connected to the next layer and has its own weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test)= mnist.load_data()\n",
    " \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (28,28)), \"The dimensions of the images are not 28 x 28.\"\n",
    "assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_test.shape[1:] == (28,28)), \"The dimensions of the images are not 28 x 28.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples=[]\n",
    " \n",
    "cols = 5\n",
    "num_classes = 10\n",
    " \n",
    "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,10))\n",
    "fig.tight_layout()\n",
    " \n",
    "for i in range(cols):\n",
    "    for j in range(num_classes):\n",
    "      x_selected = X_train[y_train == j]\n",
    "      axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))\n",
    "      axs[j][i].axis(\"off\")\n",
    "      if i == 2:\n",
    "        axs[j][i].set_title(str(j))\n",
    "        num_of_samples.append(len(x_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_of_samples)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(0, num_classes), num_of_samples)\n",
    "plt.title(\"Distribution of the train dataset\")\n",
    "plt.xlabel(\"Class number\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing:\n",
    "\n",
    "Notice the difference between CNN and artificial neural network is how we reshape the image. \n",
    "\n",
    "Previously, the image would be reshaped as a one dimensional array which are just the total number of pixels in the image. Now, we're leaving it as a 28 by 28 image but als  adding a depth of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
